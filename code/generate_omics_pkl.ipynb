{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a24b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import ogb\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "993a06a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aliciapliego/Projects/drug_synergy/AI-predict/code\n",
      "/Users/aliciapliego/Projects/drug_synergy/AI-predict\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "cwd_parent = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "# cwd_parent = os.path.abspath(os.path.join(cwd, '../../'))\n",
    "print(cwd_parent)\n",
    "\n",
    "sys.path.append(cwd_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f1ed560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepadr\n",
    "from deepadr.dataset import *\n",
    "from deepadr.utilities import *\n",
    "from deepadr.chemfeatures import *\n",
    "from deepadr.train_functions_flat import *\n",
    "from deepadr.model_gnn_ogb import GNN, DeepAdr_SiameseTrf, ExpressionNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde5a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_dir = '../data/raw/'\n",
    "processed_dir = '../data/processed/'\n",
    "up_dir = '..'\n",
    "targetdata_dir_raw = '/Users/aliciapliego/Projects/drug_synergy/AI-predict/data/processed/dataset_generation/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6ba19ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(targetdata_dir_raw, 'data_pkl.tsv'), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c3436a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_ID</th>\n",
       "      <th>ACH-000277</th>\n",
       "      <th>ACH-000837</th>\n",
       "      <th>ACH-000930</th>\n",
       "      <th>ACH-000615</th>\n",
       "      <th>ACH-000090</th>\n",
       "      <th>ACH-000147</th>\n",
       "      <th>ACH-000849</th>\n",
       "      <th>ACH-000785</th>\n",
       "      <th>ACH-001190</th>\n",
       "      <th>...</th>\n",
       "      <th>ACH-000551</th>\n",
       "      <th>ACH-000720</th>\n",
       "      <th>ACH-001196</th>\n",
       "      <th>ACH-000376</th>\n",
       "      <th>ACH-000267</th>\n",
       "      <th>ACH-000680</th>\n",
       "      <th>ACH-000481</th>\n",
       "      <th>ACH-000856</th>\n",
       "      <th>ACH-000730</th>\n",
       "      <th>ACH-000530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.146492</td>\n",
       "      <td>2.981853</td>\n",
       "      <td>4.052242</td>\n",
       "      <td>4.822220</td>\n",
       "      <td>1.263034</td>\n",
       "      <td>4.516646</td>\n",
       "      <td>2.678072</td>\n",
       "      <td>0.847997</td>\n",
       "      <td>3.893362</td>\n",
       "      <td>...</td>\n",
       "      <td>4.624686</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>2.010780</td>\n",
       "      <td>4.305971</td>\n",
       "      <td>4.175525</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>4.724105</td>\n",
       "      <td>4.174726</td>\n",
       "      <td>5.621759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.124328</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.485427</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.464668</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.807355</td>\n",
       "      <td>0.163499</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>3.481557</td>\n",
       "      <td>4.149747</td>\n",
       "      <td>2.639232</td>\n",
       "      <td>2.891419</td>\n",
       "      <td>1.726831</td>\n",
       "      <td>3.559492</td>\n",
       "      <td>4.827819</td>\n",
       "      <td>3.538538</td>\n",
       "      <td>...</td>\n",
       "      <td>2.899176</td>\n",
       "      <td>2.017922</td>\n",
       "      <td>5.140370</td>\n",
       "      <td>2.912650</td>\n",
       "      <td>2.147307</td>\n",
       "      <td>3.635754</td>\n",
       "      <td>2.780310</td>\n",
       "      <td>3.970854</td>\n",
       "      <td>3.975447</td>\n",
       "      <td>3.565597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.238787</td>\n",
       "      <td>2.881665</td>\n",
       "      <td>0.622930</td>\n",
       "      <td>3.273516</td>\n",
       "      <td>5.226123</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>1.803227</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>0.910733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>6.029232</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>5.497932</td>\n",
       "      <td>0.356144</td>\n",
       "      <td>0.042644</td>\n",
       "      <td>4.279471</td>\n",
       "      <td>3.085765</td>\n",
       "      <td>0.411426</td>\n",
       "      <td>0.464668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>4.249445</td>\n",
       "      <td>5.250583</td>\n",
       "      <td>4.321207</td>\n",
       "      <td>3.171527</td>\n",
       "      <td>0.111031</td>\n",
       "      <td>3.727920</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>4.725196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>4.532317</td>\n",
       "      <td>3.763412</td>\n",
       "      <td>2.847997</td>\n",
       "      <td>4.167519</td>\n",
       "      <td>0.097611</td>\n",
       "      <td>1.739848</td>\n",
       "      <td>0.855990</td>\n",
       "      <td>3.790772</td>\n",
       "      <td>4.123501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19174</th>\n",
       "      <td>9991</td>\n",
       "      <td>5.309613</td>\n",
       "      <td>4.902556</td>\n",
       "      <td>4.092546</td>\n",
       "      <td>3.760221</td>\n",
       "      <td>3.324811</td>\n",
       "      <td>4.984134</td>\n",
       "      <td>5.244887</td>\n",
       "      <td>5.058316</td>\n",
       "      <td>4.819668</td>\n",
       "      <td>...</td>\n",
       "      <td>5.868637</td>\n",
       "      <td>4.264536</td>\n",
       "      <td>5.034304</td>\n",
       "      <td>4.020591</td>\n",
       "      <td>5.584662</td>\n",
       "      <td>5.960697</td>\n",
       "      <td>4.760753</td>\n",
       "      <td>4.704872</td>\n",
       "      <td>4.377124</td>\n",
       "      <td>4.574707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19175</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.176323</td>\n",
       "      <td>0.613532</td>\n",
       "      <td>0.056584</td>\n",
       "      <td>0.189034</td>\n",
       "      <td>0.575312</td>\n",
       "      <td>0.978196</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250962</td>\n",
       "      <td>1.014355</td>\n",
       "      <td>0.014355</td>\n",
       "      <td>0.084064</td>\n",
       "      <td>0.286881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>9993</td>\n",
       "      <td>5.157044</td>\n",
       "      <td>5.458448</td>\n",
       "      <td>6.129077</td>\n",
       "      <td>5.028569</td>\n",
       "      <td>3.657640</td>\n",
       "      <td>4.785027</td>\n",
       "      <td>5.043957</td>\n",
       "      <td>4.965323</td>\n",
       "      <td>4.438293</td>\n",
       "      <td>...</td>\n",
       "      <td>5.864929</td>\n",
       "      <td>5.216455</td>\n",
       "      <td>4.590961</td>\n",
       "      <td>5.011675</td>\n",
       "      <td>4.121844</td>\n",
       "      <td>4.756490</td>\n",
       "      <td>4.759688</td>\n",
       "      <td>5.978424</td>\n",
       "      <td>4.508429</td>\n",
       "      <td>5.271276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>9994</td>\n",
       "      <td>3.590961</td>\n",
       "      <td>3.317594</td>\n",
       "      <td>2.744161</td>\n",
       "      <td>3.139142</td>\n",
       "      <td>2.260026</td>\n",
       "      <td>3.215679</td>\n",
       "      <td>4.186659</td>\n",
       "      <td>2.480265</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>...</td>\n",
       "      <td>3.671293</td>\n",
       "      <td>3.467279</td>\n",
       "      <td>3.544733</td>\n",
       "      <td>3.157044</td>\n",
       "      <td>4.303781</td>\n",
       "      <td>3.187451</td>\n",
       "      <td>3.196922</td>\n",
       "      <td>4.286142</td>\n",
       "      <td>2.671293</td>\n",
       "      <td>4.100978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19178</th>\n",
       "      <td>9997</td>\n",
       "      <td>4.201634</td>\n",
       "      <td>3.846995</td>\n",
       "      <td>5.068241</td>\n",
       "      <td>4.934988</td>\n",
       "      <td>4.187451</td>\n",
       "      <td>4.357552</td>\n",
       "      <td>4.420887</td>\n",
       "      <td>5.036064</td>\n",
       "      <td>2.873813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.512227</td>\n",
       "      <td>4.531069</td>\n",
       "      <td>3.526069</td>\n",
       "      <td>3.997292</td>\n",
       "      <td>2.572890</td>\n",
       "      <td>4.272023</td>\n",
       "      <td>4.563768</td>\n",
       "      <td>4.118526</td>\n",
       "      <td>4.587365</td>\n",
       "      <td>4.403949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19179 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene_ID  ACH-000277  ACH-000837  ACH-000930  ACH-000615  ACH-000090  \\\n",
       "0            1    5.146492    2.981853    4.052242    4.822220    1.263034   \n",
       "1           10    0.124328    0.286881    0.000000    0.000000    0.042644   \n",
       "2          100    0.084064    3.481557    4.149747    2.639232    2.891419   \n",
       "3         1000    0.238787    2.881665    0.622930    3.273516    5.226123   \n",
       "4        10000    0.070389    4.249445    5.250583    4.321207    3.171527   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "19174     9991    5.309613    4.902556    4.092546    3.760221    3.324811   \n",
       "19175     9992    0.695994    0.176323    0.613532    0.056584    0.189034   \n",
       "19176     9993    5.157044    5.458448    6.129077    5.028569    3.657640   \n",
       "19177     9994    3.590961    3.317594    2.744161    3.139142    2.260026   \n",
       "19178     9997    4.201634    3.846995    5.068241    4.934988    4.187451   \n",
       "\n",
       "       ACH-000147  ACH-000849  ACH-000785  ACH-001190  ...  ACH-000551  \\\n",
       "0        4.516646    2.678072    0.847997    3.893362  ...    4.624686   \n",
       "1        0.250962    0.163499    0.485427    0.111031  ...    0.000000   \n",
       "2        1.726831    3.559492    4.827819    3.538538  ...    2.899176   \n",
       "3        0.056584    1.803227    0.042644    0.910733  ...    0.189034   \n",
       "4        0.111031    3.727920    0.150560    4.725196  ...    0.536053   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "19174    4.984134    5.244887    5.058316    4.819668  ...    5.868637   \n",
       "19175    0.575312    0.978196    0.226509    0.000000  ...    0.070389   \n",
       "19176    4.785027    5.043957    4.965323    4.438293  ...    5.864929   \n",
       "19177    3.215679    4.186659    2.480265    3.584963  ...    3.671293   \n",
       "19178    4.357552    4.420887    5.036064    2.873813  ...    3.512227   \n",
       "\n",
       "       ACH-000720  ACH-001196  ACH-000376  ACH-000267  ACH-000680  ACH-000481  \\\n",
       "0        0.695994    2.010780    4.305971    4.175525    0.250962    0.704872   \n",
       "1        0.137504    0.464668    0.250962    0.000000    1.807355    0.163499   \n",
       "2        2.017922    5.140370    2.912650    2.147307    3.635754    2.780310   \n",
       "3        6.029232    0.014355    5.497932    0.356144    0.042644    4.279471   \n",
       "4        4.532317    3.763412    2.847997    4.167519    0.097611    1.739848   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19174    4.264536    5.034304    4.020591    5.584662    5.960697    4.760753   \n",
       "19175    0.263034    0.000000    0.250962    1.014355    0.014355    0.084064   \n",
       "19176    5.216455    4.590961    5.011675    4.121844    4.756490    4.759688   \n",
       "19177    3.467279    3.544733    3.157044    4.303781    3.187451    3.196922   \n",
       "19178    4.531069    3.526069    3.997292    2.572890    4.272023    4.563768   \n",
       "\n",
       "       ACH-000856  ACH-000730  ACH-000530  \n",
       "0        4.724105    4.174726    5.621759  \n",
       "1        0.070389    0.056584    0.000000  \n",
       "2        3.970854    3.975447    3.565597  \n",
       "3        3.085765    0.411426    0.464668  \n",
       "4        0.855990    3.790772    4.123501  \n",
       "...           ...         ...         ...  \n",
       "19174    4.704872    4.377124    4.574707  \n",
       "19175    0.286881    0.000000    0.263034  \n",
       "19176    5.978424    4.508429    5.271276  \n",
       "19177    4.286142    2.671293    4.100978  \n",
       "19178    4.118526    4.587365    4.403949  \n",
       "\n",
       "[19179 rows x 120 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rna = pd.read_csv('../data/processed/gene_expression_data_preprocessed.csv')\n",
    "df_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f606e027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_ID</th>\n",
       "      <th>ACH-000277</th>\n",
       "      <th>ACH-000837</th>\n",
       "      <th>ACH-000930</th>\n",
       "      <th>ACH-000615</th>\n",
       "      <th>ACH-000090</th>\n",
       "      <th>ACH-000147</th>\n",
       "      <th>ACH-000849</th>\n",
       "      <th>ACH-000785</th>\n",
       "      <th>ACH-001190</th>\n",
       "      <th>...</th>\n",
       "      <th>ACH-000551</th>\n",
       "      <th>ACH-000720</th>\n",
       "      <th>ACH-001196</th>\n",
       "      <th>ACH-000376</th>\n",
       "      <th>ACH-000267</th>\n",
       "      <th>ACH-000680</th>\n",
       "      <th>ACH-000481</th>\n",
       "      <th>ACH-000856</th>\n",
       "      <th>ACH-000730</th>\n",
       "      <th>ACH-000530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.031555</td>\n",
       "      <td>0.944715</td>\n",
       "      <td>0.756541</td>\n",
       "      <td>1.206992</td>\n",
       "      <td>1.211438</td>\n",
       "      <td>0.768499</td>\n",
       "      <td>1.341251</td>\n",
       "      <td>1.452116</td>\n",
       "      <td>0.905456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002602</td>\n",
       "      <td>0.925300</td>\n",
       "      <td>1.029293</td>\n",
       "      <td>1.096465</td>\n",
       "      <td>1.008494</td>\n",
       "      <td>0.741872</td>\n",
       "      <td>1.354908</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>0.806532</td>\n",
       "      <td>1.173974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.093802</td>\n",
       "      <td>0.546255</td>\n",
       "      <td>0.744336</td>\n",
       "      <td>0.835375</td>\n",
       "      <td>0.784642</td>\n",
       "      <td>0.832593</td>\n",
       "      <td>0.861512</td>\n",
       "      <td>0.640122</td>\n",
       "      <td>0.977407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>1.469678</td>\n",
       "      <td>1.037913</td>\n",
       "      <td>0.574689</td>\n",
       "      <td>1.076897</td>\n",
       "      <td>1.076598</td>\n",
       "      <td>1.024159</td>\n",
       "      <td>0.747238</td>\n",
       "      <td>0.707131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1.787550</td>\n",
       "      <td>1.471560</td>\n",
       "      <td>2.021517</td>\n",
       "      <td>0.925605</td>\n",
       "      <td>1.251417</td>\n",
       "      <td>1.356372</td>\n",
       "      <td>1.037354</td>\n",
       "      <td>1.222511</td>\n",
       "      <td>1.282751</td>\n",
       "      <td>...</td>\n",
       "      <td>1.003322</td>\n",
       "      <td>1.122776</td>\n",
       "      <td>1.075256</td>\n",
       "      <td>1.021755</td>\n",
       "      <td>0.580835</td>\n",
       "      <td>1.416126</td>\n",
       "      <td>1.345187</td>\n",
       "      <td>1.042199</td>\n",
       "      <td>1.296084</td>\n",
       "      <td>0.834743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.685398</td>\n",
       "      <td>0.922892</td>\n",
       "      <td>1.081175</td>\n",
       "      <td>0.817158</td>\n",
       "      <td>1.130757</td>\n",
       "      <td>0.858228</td>\n",
       "      <td>0.818851</td>\n",
       "      <td>0.386752</td>\n",
       "      <td>0.974166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172393</td>\n",
       "      <td>0.808366</td>\n",
       "      <td>1.165846</td>\n",
       "      <td>1.016473</td>\n",
       "      <td>1.003177</td>\n",
       "      <td>0.810428</td>\n",
       "      <td>1.085301</td>\n",
       "      <td>1.038358</td>\n",
       "      <td>0.950280</td>\n",
       "      <td>1.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1.108415</td>\n",
       "      <td>1.183689</td>\n",
       "      <td>1.529492</td>\n",
       "      <td>0.994248</td>\n",
       "      <td>1.320970</td>\n",
       "      <td>1.125498</td>\n",
       "      <td>1.235262</td>\n",
       "      <td>1.218143</td>\n",
       "      <td>1.092804</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206254</td>\n",
       "      <td>1.197469</td>\n",
       "      <td>0.985526</td>\n",
       "      <td>1.004714</td>\n",
       "      <td>1.011931</td>\n",
       "      <td>1.047703</td>\n",
       "      <td>1.319866</td>\n",
       "      <td>1.014745</td>\n",
       "      <td>1.046404</td>\n",
       "      <td>1.044751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19174</th>\n",
       "      <td>9991</td>\n",
       "      <td>1.380481</td>\n",
       "      <td>0.925425</td>\n",
       "      <td>0.767892</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.811080</td>\n",
       "      <td>1.381067</td>\n",
       "      <td>0.869019</td>\n",
       "      <td>0.918873</td>\n",
       "      <td>0.973519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997630</td>\n",
       "      <td>0.964079</td>\n",
       "      <td>1.302591</td>\n",
       "      <td>1.029486</td>\n",
       "      <td>1.013011</td>\n",
       "      <td>1.333506</td>\n",
       "      <td>0.840148</td>\n",
       "      <td>1.017062</td>\n",
       "      <td>1.110135</td>\n",
       "      <td>0.766850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19175</th>\n",
       "      <td>9992</td>\n",
       "      <td>1.042669</td>\n",
       "      <td>0.933492</td>\n",
       "      <td>1.191881</td>\n",
       "      <td>0.951660</td>\n",
       "      <td>1.238675</td>\n",
       "      <td>1.077861</td>\n",
       "      <td>1.309751</td>\n",
       "      <td>0.919539</td>\n",
       "      <td>0.970371</td>\n",
       "      <td>...</td>\n",
       "      <td>1.193927</td>\n",
       "      <td>0.921105</td>\n",
       "      <td>1.009351</td>\n",
       "      <td>1.230122</td>\n",
       "      <td>1.004917</td>\n",
       "      <td>0.791777</td>\n",
       "      <td>0.804547</td>\n",
       "      <td>0.993864</td>\n",
       "      <td>0.856674</td>\n",
       "      <td>0.972384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>9993</td>\n",
       "      <td>1.009506</td>\n",
       "      <td>1.258480</td>\n",
       "      <td>1.235767</td>\n",
       "      <td>1.325867</td>\n",
       "      <td>0.751190</td>\n",
       "      <td>0.769720</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>1.088386</td>\n",
       "      <td>1.275583</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066792</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>1.157416</td>\n",
       "      <td>0.996319</td>\n",
       "      <td>1.036152</td>\n",
       "      <td>0.773341</td>\n",
       "      <td>1.055446</td>\n",
       "      <td>1.002974</td>\n",
       "      <td>1.136541</td>\n",
       "      <td>0.772943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>9994</td>\n",
       "      <td>1.129907</td>\n",
       "      <td>0.935139</td>\n",
       "      <td>0.779656</td>\n",
       "      <td>1.126231</td>\n",
       "      <td>0.790715</td>\n",
       "      <td>0.869332</td>\n",
       "      <td>1.453172</td>\n",
       "      <td>0.833466</td>\n",
       "      <td>0.977201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988313</td>\n",
       "      <td>0.886080</td>\n",
       "      <td>0.780440</td>\n",
       "      <td>0.991999</td>\n",
       "      <td>1.031005</td>\n",
       "      <td>0.971278</td>\n",
       "      <td>0.988014</td>\n",
       "      <td>1.020099</td>\n",
       "      <td>0.909038</td>\n",
       "      <td>0.994358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19178</th>\n",
       "      <td>9997</td>\n",
       "      <td>1.014555</td>\n",
       "      <td>0.924106</td>\n",
       "      <td>1.229300</td>\n",
       "      <td>1.325867</td>\n",
       "      <td>0.751190</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>1.100519</td>\n",
       "      <td>1.088386</td>\n",
       "      <td>0.579064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721127</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>0.943937</td>\n",
       "      <td>1.001104</td>\n",
       "      <td>0.608849</td>\n",
       "      <td>0.773317</td>\n",
       "      <td>1.057099</td>\n",
       "      <td>0.991077</td>\n",
       "      <td>1.136541</td>\n",
       "      <td>0.772943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19179 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene_ID  ACH-000277  ACH-000837  ACH-000930  ACH-000615  ACH-000090  \\\n",
       "0            1    1.031555    0.944715    0.756541    1.206992    1.211438   \n",
       "1           10    1.093802    0.546255    0.744336    0.835375    0.784642   \n",
       "2          100    1.787550    1.471560    2.021517    0.925605    1.251417   \n",
       "3         1000    0.685398    0.922892    1.081175    0.817158    1.130757   \n",
       "4        10000    1.108415    1.183689    1.529492    0.994248    1.320970   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "19174     9991    1.380481    0.925425    0.767892    0.898100    0.811080   \n",
       "19175     9992    1.042669    0.933492    1.191881    0.951660    1.238675   \n",
       "19176     9993    1.009506    1.258480    1.235767    1.325867    0.751190   \n",
       "19177     9994    1.129907    0.935139    0.779656    1.126231    0.790715   \n",
       "19178     9997    1.014555    0.924106    1.229300    1.325867    0.751190   \n",
       "\n",
       "       ACH-000147  ACH-000849  ACH-000785  ACH-001190  ...  ACH-000551  \\\n",
       "0        0.768499    1.341251    1.452116    0.905456  ...    1.002602   \n",
       "1        0.832593    0.861512    0.640122    0.977407  ...    0.982000   \n",
       "2        1.356372    1.037354    1.222511    1.282751  ...    1.003322   \n",
       "3        0.858228    0.818851    0.386752    0.974166  ...    1.172393   \n",
       "4        1.125498    1.235262    1.218143    1.092804  ...    1.206254   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "19174    1.381067    0.869019    0.918873    0.973519  ...    0.997630   \n",
       "19175    1.077861    1.309751    0.919539    0.970371  ...    1.193927   \n",
       "19176    0.769720    1.100519    1.088386    1.275583  ...    2.066792   \n",
       "19177    0.869332    1.453172    0.833466    0.977201  ...    0.988313   \n",
       "19178    0.784855    1.100519    1.088386    0.579064  ...    0.721127   \n",
       "\n",
       "       ACH-000720  ACH-001196  ACH-000376  ACH-000267  ACH-000680  ACH-000481  \\\n",
       "0        0.925300    1.029293    1.096465    1.008494    0.741872    1.354908   \n",
       "1        0.915472    1.469678    1.037913    0.574689    1.076897    1.076598   \n",
       "2        1.122776    1.075256    1.021755    0.580835    1.416126    1.345187   \n",
       "3        0.808366    1.165846    1.016473    1.003177    0.810428    1.085301   \n",
       "4        1.197469    0.985526    1.004714    1.011931    1.047703    1.319866   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19174    0.964079    1.302591    1.029486    1.013011    1.333506    0.840148   \n",
       "19175    0.921105    1.009351    1.230122    1.004917    0.791777    0.804547   \n",
       "19176    0.975385    1.157416    0.996319    1.036152    0.773341    1.055446   \n",
       "19177    0.886080    0.780440    0.991999    1.031005    0.971278    0.988014   \n",
       "19178    0.975385    0.943937    1.001104    0.608849    0.773317    1.057099   \n",
       "\n",
       "       ACH-000856  ACH-000730  ACH-000530  \n",
       "0        0.980352    0.806532    1.173974  \n",
       "1        1.024159    0.747238    0.707131  \n",
       "2        1.042199    1.296084    0.834743  \n",
       "3        1.038358    0.950280    1.001396  \n",
       "4        1.014745    1.046404    1.044751  \n",
       "...           ...         ...         ...  \n",
       "19174    1.017062    1.110135    0.766850  \n",
       "19175    0.993864    0.856674    0.972384  \n",
       "19176    1.002974    1.136541    0.772943  \n",
       "19177    1.020099    0.909038    0.994358  \n",
       "19178    0.991077    1.136541    0.772943  \n",
       "\n",
       "[19179 rows x 120 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cnv = pd.read_csv('../data/processed/cnv_data_preprocessed.csv')\n",
    "df_cnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d05a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene_ID</th>\n",
       "      <th>ACH-000277</th>\n",
       "      <th>ACH-000837</th>\n",
       "      <th>ACH-000930</th>\n",
       "      <th>ACH-000615</th>\n",
       "      <th>ACH-000090</th>\n",
       "      <th>ACH-000147</th>\n",
       "      <th>ACH-000849</th>\n",
       "      <th>ACH-000785</th>\n",
       "      <th>ACH-001190</th>\n",
       "      <th>...</th>\n",
       "      <th>ACH-000551</th>\n",
       "      <th>ACH-000720</th>\n",
       "      <th>ACH-001196</th>\n",
       "      <th>ACH-000376</th>\n",
       "      <th>ACH-000267</th>\n",
       "      <th>ACH-000680</th>\n",
       "      <th>ACH-000481</th>\n",
       "      <th>ACH-000856</th>\n",
       "      <th>ACH-000730</th>\n",
       "      <th>ACH-000530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19174</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19175</th>\n",
       "      <td>9992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19176</th>\n",
       "      <td>9993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19178</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19179 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene_ID  ACH-000277  ACH-000837  ACH-000930  ACH-000615  ACH-000090  \\\n",
       "0            1         0.0         0.0         0.0         0.0         0.0   \n",
       "1           10         0.0         0.0         0.0         0.0         0.0   \n",
       "2          100         0.0         0.0         0.0         0.0         0.0   \n",
       "3         1000         0.0         0.0         2.0         0.0         0.0   \n",
       "4        10000         0.0         0.0         2.0         0.0         0.0   \n",
       "...        ...         ...         ...         ...         ...         ...   \n",
       "19174     9991         0.0         0.0         0.0         0.0         0.0   \n",
       "19175     9992         0.0         0.0         0.0         0.0         0.0   \n",
       "19176     9993         0.0         0.0         0.0         0.0         0.0   \n",
       "19177     9994         0.0         0.0         0.0         0.0         0.0   \n",
       "19178     9997         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "       ACH-000147  ACH-000849  ACH-000785  ACH-001190  ...  ACH-000551  \\\n",
       "0             0.0         0.0         0.0         0.0  ...         0.0   \n",
       "1             0.0         0.0         0.0         0.0  ...         0.0   \n",
       "2             0.0         0.0         0.0         0.0  ...         0.0   \n",
       "3             0.0         0.0         0.0         0.0  ...         2.0   \n",
       "4             0.0         0.0         0.0         0.0  ...         2.0   \n",
       "...           ...         ...         ...         ...  ...         ...   \n",
       "19174         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "19175         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "19176         0.0         0.0         2.0         0.0  ...         0.0   \n",
       "19177         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "19178         0.0         0.0         0.0         0.0  ...         0.0   \n",
       "\n",
       "       ACH-000720  ACH-001196  ACH-000376  ACH-000267  ACH-000680  ACH-000481  \\\n",
       "0             0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "1             0.0         0.0         0.0         2.0         0.0         0.0   \n",
       "2             0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "3             0.0         0.0         0.0         2.0         0.0         0.0   \n",
       "4             0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "19174         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "19175         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "19176         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "19177         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "19178         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "       ACH-000856  ACH-000730  ACH-000530  \n",
       "0             0.0         0.0         0.0  \n",
       "1             0.0         0.0         0.0  \n",
       "2             0.0         0.0         0.0  \n",
       "3             0.0         0.0         0.0  \n",
       "4             0.0         0.0         0.0  \n",
       "...           ...         ...         ...  \n",
       "19174         0.0         0.0         0.0  \n",
       "19175         0.0         0.0         0.0  \n",
       "19176         0.0         0.0         0.0  \n",
       "19177         0.0         0.0         0.0  \n",
       "19178         0.0         0.0         0.0  \n",
       "\n",
       "[19179 rows x 120 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mut = pd.read_csv('../data/processed/mutation_data_preprocessed.csv')\n",
    "df_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78992928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233326, 19179)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rna_array = np.array([df_rna[str(c)].values for c in data[\"Cell_ID\"]])\n",
    "rna_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d9e7f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233326, 19179)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnv_array = np.array([df_cnv[str(c)].values for c in data[\"Cell_ID\"]])\n",
    "cnv_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ab364a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233326, 19179)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mut_array = np.array([df_mut[str(c)].values for c in data[\"Cell_ID\"]])\n",
    "mut_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a95d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "omics_array = np.array([np.array(df_rna),np.array(df_cnv), np.array(df_mut)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa57cfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 19179, 120)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omics_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd414fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReaderWriter.dump_data(omics_array, os.path.join(targetdata_dir_raw, 'omics.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c378001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_current_dir /Users/aliciapliego/Projects/drug_synergy/AI-predict/deepadr\n"
     ]
    }
   ],
   "source": [
    "targetdata_dir = create_directory(os.path.join(processed_dir, 'dataset_generation'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1528fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.62 ms, sys: 643 ms, total: 647 ms\n",
      "Wall time: 654 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# In order to generate a new Dataset, first remove the generated files above\n",
    "\n",
    "dataset = MoleculeDataset(root=targetdata_dir, dataset='tdcSynergy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f208e0",
   "metadata": {},
   "source": [
    "### Explore the data generated by the MoleculeDataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da58355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geom_filter = torch.load('/Users/aliciapliego/Projects/drug_synergy/AI-predict/data/processed/dataset_generation/processed/geometric_data_processed.pt') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "220c9ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PairData(edge_index_a=[2, 15305430], x_a=[7069479, 9], edge_attr_a=[15305430, 3], edge_index_b=[2, 13680958], x_b=[6405928, 9], edge_attr_b=[13680958, 3], id=[233326], y=[233326, 4]),\n",
       " defaultdict(dict,\n",
       "             {'edge_index_a': tensor([       0,       66,      132,  ..., 15305230, 15305300, 15305430]),\n",
       "              'x_a': tensor([      0,      30,      60,  ..., 7069391, 7069422, 7069479]),\n",
       "              'edge_attr_a': tensor([       0,       66,      132,  ..., 15305230, 15305300, 15305430]),\n",
       "              'edge_index_b': tensor([       0,       72,      134,  ..., 13680754, 13680856, 13680958]),\n",
       "              'x_b': tensor([      0,      31,      62,  ..., 6405836, 6405882, 6405928]),\n",
       "              'edge_attr_b': tensor([       0,       72,      134,  ..., 13680754, 13680856, 13680958]),\n",
       "              'id': tensor([     0,      1,      2,  ..., 233324, 233325, 233326]),\n",
       "              'y': tensor([     0,      1,      2,  ..., 233324, 233325, 233326])}))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c7f81f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_transform = torch.load('/Users/aliciapliego/Projects/drug_synergy/AI-predict/data/processed/dataset_generation/processed/pre_transform.pt') \n",
    "pre_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b832083d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_filter = torch.load('/Users/aliciapliego/Projects/drug_synergy/AI-predict/data/processed/dataset_generation/processed/pre_filter.pt') \n",
    "pre_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e904a30",
   "metadata": {},
   "source": [
    "## Hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd35cc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MoleculeDataset(233326):\n",
      "====================\n",
      "Number of graphs: 233326\n",
      "Number of features: 9\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16df5087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used_dataset = dataset\n",
    "\n",
    "# If you want to use a smaller subset of the dataset for testing\n",
    "smaller_dataset_len = int(len(dataset)/1)\n",
    "used_dataset = dataset[:smaller_dataset_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29a24b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeDataset(233326)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0a6eae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_cpu = get_device(to_gpu=False)\n",
    "n_gpu = torch.cuda.device_count()\n",
    "n_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f6d7748",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multiclass-multioutput' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c7/mrt2qhgn0fv35v7r9wj3gj6w0000gn/T/ipykernel_34725/3175594570.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fold_partitions = get_stratified_partitions(used_dataset.data.y[:smaller_dataset_len],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                             num_folds=5, valid_set_portion=0.1, random_state=42)\n",
      "\u001b[0;32m~/Projects/drug_synergy/AI-predict/deepadr/dataset.py\u001b[0m in \u001b[0;36mget_stratified_partitions\u001b[0;34m(y, num_folds, valid_set_portion, random_state)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0mfold_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf_trte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mx_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mallowed_target_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype_of_target_y\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \"Supported target types are: {}. Got {!r} instead.\".format(\n\u001b[1;32m    654\u001b[0m                     \u001b[0mallowed_target_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_of_target_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Supported target types are: ('binary', 'multiclass'). Got 'multiclass-multioutput' instead."
     ]
    }
   ],
   "source": [
    "fold_partitions = get_stratified_partitions(used_dataset.data.y[:smaller_dataset_len],\n",
    "                                            num_folds=5, valid_set_portion=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(queue, used_dataset, gpu_num, tp, exp_dir, partition): #\n",
    "    \n",
    "    num_classes = 2\n",
    "    \n",
    "    targetdata_dir_raw = os.path.abspath(exp_dir + \"/../../raw\")\n",
    "    targetdata_dir_processed = os.path.abspath(exp_dir + \"/../../processed\")\n",
    "    \n",
    "    state_dict_dir = os.path.join(exp_dir, 'modelstates')\n",
    "    \n",
    "    #device_gpu = get_device(True, index=gpu_num)\n",
    "    #print(\"gpu:\", device_gpu)\n",
    "    \n",
    "    # Serialize data into file:\n",
    "    json.dump( tp, open( exp_dir + \"/hyperparameters.json\", 'w' ) )\n",
    "    \n",
    "    tp['nonlin_func'] = nn.ReLU()\n",
    "    \n",
    "    expression_scaler = TorchStandardScaler()\n",
    "    expression_scaler.fit(used_dataset.data.expression[partition['train']])\n",
    "    \n",
    "    train_dataset = Subset(used_dataset, partition['train'])\n",
    "    val_dataset = Subset(used_dataset, partition['validation'])\n",
    "    test_dataset = Subset(used_dataset, partition['test'])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=tp[\"batch_size\"], shuffle=True, follow_batch=['x_a', 'x_b'])\n",
    "    valid_loader = DataLoader(val_dataset, batch_size=tp[\"batch_size\"], shuffle=False, follow_batch=['x_a', 'x_b'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=tp[\"batch_size\"], shuffle=False, follow_batch=['x_a', 'x_b'])\n",
    "    \n",
    "    loaders = {\"train\": train_loader, \"valid\": valid_loader, \"test\": test_loader}\n",
    "\n",
    "    gnn_model = GNN(gnn_type = tp[\"gnn_type\"], \n",
    "                num_layer = tp[\"num_layer\"], \n",
    "                emb_dim = tp[\"emb_dim\"], \n",
    "                drop_ratio = 0.5, \n",
    "                JK = \"multilayer\", #last\n",
    "                graph_pooling = tp[\"graph_pooling\"],\n",
    "                virtual_node = False,\n",
    "                with_edge_attr=False).to(device=device_gpu, dtype=fdtype)\n",
    "\n",
    "\n",
    "    expression_model = DeepSynergy(D_in=(2*tp[\"emb_dim\"])+tp[\"expression_input_size\"],\n",
    "                                   H1=tp['exp_H1'], H2=tp['exp_H2'], drop=tp['p_dropout']).to(device=device_gpu, dtype=fdtype)\n",
    "\n",
    "    gene_attn_model = GeneEmbAttention(input_dim=tp[\"expression_input_size\"]).to(device=device_gpu, dtype=fdtype)\n",
    "\n",
    "    models_param = list(gnn_model.parameters()) + list(expression_model.parameters()) + list(gene_attn_model.parameters())\n",
    "\n",
    "\n",
    "    model_name = \"ogb\"\n",
    "    models = [(gnn_model, f'{model_name}_GNN'),\n",
    "              (expression_model, f'{model_name}_Expression'),\n",
    "\n",
    "              (gene_attn_model, f'{model_name}_GeneAttn'),\n",
    "             ]\n",
    "    \n",
    "\n",
    "    y_weights = compute_class_weights(used_dataset.data.y[partition['train']])\n",
    "    class_weights = torch.tensor(y_weights).type(fdtype).to(device_gpu)\n",
    "\n",
    "    # from IPython.display import Javascript\n",
    "    # display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
    "\n",
    "    num_iter = len(train_loader)  # num_train_samples/batch_size\n",
    "    c_step_size = int(np.ceil(5*num_iter))  # this should be 2-10 times num_iter\n",
    "\n",
    "    base_lr = tp['base_lr']\n",
    "    max_lr = tp['max_lr_mul']*base_lr  # 3-5 times base_lr\n",
    "    optimizer = torch.optim.Adam(models_param, weight_decay=tp[\"l2_reg\"], lr=base_lr)\n",
    "    cyc_scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=c_step_size,\n",
    "                                                    mode='triangular', cycle_momentum=False)\n",
    "\n",
    "    loss_nlll = torch.nn.NLLLoss(weight=class_weights, reduction='mean')  # negative log likelihood loss\n",
    "    loss_contrastive = ContrastiveLoss(0.5, reduction='mean')\n",
    "    \n",
    "    \n",
    "    valid_curve_aupr = []\n",
    "    test_curve_aupr = []\n",
    "    train_curve_aupr = []\n",
    "    \n",
    "    valid_curve_auc = []\n",
    "    test_curve_auc = []\n",
    "    train_curve_auc = []\n",
    "    \n",
    "    best_fscore = 0\n",
    "    best_epoch = 0\n",
    "      \n",
    "\n",
    "    for epoch in range(tp[\"num_epochs\"]):\n",
    "        print(\"=====Epoch {}\".format(epoch))\n",
    "        print('Training...')\n",
    "        \n",
    "        for m, m_name in models:\n",
    "            m.train()\n",
    "\n",
    "        for i_batch, batch in enumerate(tqdm(train_loader, desc=\"Iteration\")):\n",
    "            batch = batch.to(device_gpu)\n",
    "\n",
    "            h_a = gnn_model(batch.x_a, batch.edge_index_a, batch.edge_attr_a, batch.x_a_batch)\n",
    "            h_b = gnn_model(batch.x_b, batch.edge_index_b, batch.edge_attr_b, batch.x_b_batch)\n",
    "            \n",
    "            expression_norm = expression_scaler.transform_ondevice(batch.expression, device=device_gpu) \n",
    "            h_e, _ = gene_attn_model(expression_norm.type(fdtype))\n",
    "            \n",
    "            triplet = torch.cat([h_a, h_b, h_e], axis=-1)\n",
    "\n",
    "            logsoftmax_scores = expression_model(triplet)\n",
    "\n",
    "            loss = loss_nlll(logsoftmax_scores, batch.y.type(torch.long))            \n",
    "\n",
    "            loss.backward()  # Derive gradients.\n",
    "            optimizer.step()  # Update parameters based on gradients.\n",
    "            cyc_scheduler.step() # after each batch step the scheduler\n",
    "            optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "        print('Evaluating...')\n",
    "\n",
    "        perfs = {}\n",
    "\n",
    "        for dsettype in [\"train\", \"valid\"]:\n",
    "            for m, m_name in models:\n",
    "                m.eval()\n",
    "\n",
    "            pred_class = []\n",
    "            ref_class = []\n",
    "            prob_scores = []\n",
    "            \n",
    "            l_ids = []\n",
    "           \n",
    "\n",
    "\n",
    "        #     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "            for i_batch, batch in enumerate(tqdm(loaders[dsettype], desc=\"Iteration\")):\n",
    "                batch = batch.to(device_gpu)\n",
    "                h_a = gnn_model(batch.x_a, batch.edge_index_a, batch.edge_attr_a, batch.x_a_batch)\n",
    "                h_b = gnn_model(batch.x_b, batch.edge_index_b, batch.edge_attr_b, batch.x_b_batch)\n",
    "\n",
    "                expression_norm = expression_scaler.transform_ondevice(batch.expression, device=device_gpu) \n",
    "                h_e, _ = gene_attn_model(expression_norm.type(fdtype))\n",
    "\n",
    "\n",
    "                triplet = torch.cat([h_a, h_b, h_e], axis=-1)\n",
    "                \n",
    "                logsoftmax_scores = expression_model(triplet)\n",
    "\n",
    "\n",
    "                __, y_pred_clss = torch.max(logsoftmax_scores, -1)\n",
    "\n",
    "                y_pred_prob  = torch.exp(logsoftmax_scores.detach().cpu()).numpy()\n",
    "\n",
    "                pred_class.extend(y_pred_clss.view(-1).tolist())\n",
    "                ref_class.extend(batch.y.view(-1).tolist())\n",
    "                prob_scores.append(y_pred_prob)\n",
    "                l_ids.extend(batch.id.view(-1).tolist())\n",
    "\n",
    "            prob_scores_arr = np.concatenate(prob_scores, axis=0)\n",
    "\n",
    "            dset_perf = perfmetric_report(pred_class, ref_class, prob_scores_arr[:,1], epoch,\n",
    "                                          outlog = os.path.join(exp_dir, dsettype + \".log\"))\n",
    "            \n",
    "            perfs[dsettype] = dset_perf\n",
    "            \n",
    "            if (dsettype==\"valid\"):\n",
    "                \n",
    "                fscore = F_score(perfs['valid'].s_aupr, perfs['valid'].s_auc)\n",
    "                if (fscore > best_fscore):\n",
    "                    best_fscore = fscore\n",
    "                    best_epoch = epoch\n",
    "                    \n",
    "                    for m, m_name in models:\n",
    "                        torch.save(m.state_dict(), os.path.join(state_dict_dir, '{}.pkl'.format(m_name)))\n",
    "\n",
    "        print({'Train': perfs['train'], 'Validation': perfs['valid']})\n",
    "\n",
    "        \n",
    "        train_curve_aupr.append(perfs['train'].s_aupr)\n",
    "        valid_curve_aupr.append(perfs['valid'].s_aupr)\n",
    "        test_curve_aupr.append(0.0)\n",
    "\n",
    "        \n",
    "        train_curve_auc.append(perfs['train'].s_auc)\n",
    "        valid_curve_auc.append(perfs['valid'].s_auc)\n",
    "        test_curve_auc.append(0.0)\n",
    "\n",
    "\n",
    "    print('Finished training and validating!')\n",
    "        \n",
    "        \n",
    "    for dsettype in [\"test\"]:\n",
    "        \n",
    "        if(len(os.listdir(state_dict_dir)) > 0):  # load state dictionary of saved models\n",
    "            for m, m_name in models:\n",
    "                m.load_state_dict(torch.load(os.path.join(state_dict_dir, '{}.pkl'.format(m_name)), map_location=device_gpu))\n",
    "\n",
    "        \n",
    "        for m, m_name in models:\n",
    "            m.eval()\n",
    "\n",
    "        pred_class = []\n",
    "        ref_class = []\n",
    "        prob_scores = []\n",
    "\n",
    "        l_ids = []\n",
    "\n",
    "\n",
    "    #     for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        for i_batch, batch in enumerate(tqdm(loaders[dsettype], desc=\"Iteration\")):\n",
    "            batch = batch.to(device_gpu)\n",
    "            h_a = gnn_model(batch.x_a, batch.edge_index_a, batch.edge_attr_a, batch.x_a_batch)\n",
    "            h_b = gnn_model(batch.x_b, batch.edge_index_b, batch.edge_attr_b, batch.x_b_batch)\n",
    "\n",
    "            expression_norm = expression_scaler.transform_ondevice(batch.expression, device=device_gpu) \n",
    "            h_e, _ = gene_attn_model(expression_norm.type(fdtype))\n",
    "\n",
    "\n",
    "            triplet = torch.cat([h_a, h_b, h_e], axis=-1)\n",
    "\n",
    "            logsoftmax_scores = expression_model(triplet)\n",
    "\n",
    "\n",
    "            __, y_pred_clss = torch.max(logsoftmax_scores, -1)\n",
    "\n",
    "            y_pred_prob  = torch.exp(logsoftmax_scores.detach().cpu()).numpy()\n",
    "\n",
    "            pred_class.extend(y_pred_clss.view(-1).tolist())\n",
    "            ref_class.extend(batch.y.view(-1).tolist())\n",
    "            prob_scores.append(y_pred_prob)\n",
    "            l_ids.extend(batch.id.view(-1).tolist())\n",
    "\n",
    "        prob_scores_arr = np.concatenate(prob_scores, axis=0)\n",
    "\n",
    "        dset_perf = perfmetric_report(pred_class, ref_class, prob_scores_arr[:,1], epoch,\n",
    "                                      outlog = os.path.join(exp_dir, dsettype + \".log\"))\n",
    "\n",
    "        perfs[dsettype] = dset_perf\n",
    "\n",
    "        if (dsettype==\"test\"):\n",
    "\n",
    "            predictions_df = build_predictions_df(l_ids, ref_class, pred_class, prob_scores_arr)\n",
    "            predictions_df.to_csv(os.path.join(exp_dir, 'predictions', f'epoch_{epoch}_predictions_{dsettype}.csv'))\n",
    "            \n",
    "        print({'Test': perfs['test']})\n",
    "\n",
    "        test_curve_aupr.pop()\n",
    "        test_curve_aupr.append(perfs['test'].s_aupr)\n",
    "\n",
    "        test_curve_auc.pop()\n",
    "        test_curve_auc.append(perfs['test'].s_auc)\n",
    "\n",
    "    print('Finished testing!')\n",
    "\n",
    "    df_curves = pd.DataFrame(np.array([train_curve_aupr, valid_curve_aupr, test_curve_aupr,\n",
    "                                       train_curve_auc, valid_curve_auc, test_curve_auc]).T)\n",
    "    df_curves.columns = ['train_aupr', 'valid_aupr', 'test_aupr', 'train_auc', 'valid_auc', 'test_auc']\n",
    "    df_curves.index.name = \"epoch\"\n",
    "    df_curves.to_csv(exp_dir + \"/curves.csv\")\n",
    "    sns.lineplot(data=df_curves).figure.savefig(exp_dir + \"/curves.png\")\n",
    "    \n",
    "    queue.put(gpu_num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
